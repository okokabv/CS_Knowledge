1. MLops              
  - MLOPs는 ML 모델의 개발, 배포 및 유지보수를 간소화하기 위해 ML과 DevOps 관행을 결합한 방법론이다. MLOps는 DevOps와 다음과 같은 몇 가지 주요 특성은 다음과 같다.            
 * CI/CD: MLOps는 ML 워크플로우에서 코드, 데이터 및 모델 업데이트의 지속적인 주기가 필요함을 강조한다. 이 접근 방식은 일관되고 신뢰할 수 있는 결과를 보장하기 위해 가능한 한 자동화해야 다.
 * 자동화: DevOps와 마찬가지로 MLOps는 ML 라이프사이클 전반에 걸쳐 자동화의 중요성을 강조한다. ML 워크플로우에서 데이터 처리, 모델 교육 및 배포와 같은 중요한 단계를 자동화하면 보다 효율적이고 안정적인 워크플로우를 얻을 수 있다.
 * 협업 및 투명성: MLOps는 ML 모델을 개발하고 구축하는 팀 간에 공유된 지식과 전문 지식을 공유하는 협업 및 투명한 문화를 장려한다. 이는 핸드오프 기대치가 더 표준화될 것이기 때문에 프로세스를 간소화하는 데 도움이 된다.
 * 코드로서의 인프라(IaC): DevOps와 MLOps는 "Infrastructure as code" 접근 방식을 채택하고 있으며, 이 방식은 인프라를 코드로 취급하고 버전 제어 시스템을 통해 관리한다. 이러한 접근 방식을 통해 팀은 인프라 변화를 보다 효율적이고 재현성 있게 관리할 수 있다.
 * 테스트 및 모니터링: MLOps 및 DevOps는 일관되고 신뢰할 수 있는 결과를 보장하기 위해 테스트 및 모니터링의 중요성을 강조한다. MLOps에서는 ML 모델의 정확도와 성능을 시간에 따라 테스트하고 모니터링하는 것이 포함된다.
 * 유연성 및 민첩성: DevOps와 MLOps는 변화하는 비즈니스 요구와 요구사항에 대응하는 유연성과 민첩성을 강조한다. 즉, ML 모델을 신속하게 구축하고 반복하여 변화하는 비즈니스 요구에 대응할 수 있다.
결론적으로 ML은 모델이 기본적으로 예측을 생성하는 데 사용되는 블랙박스이기 때문에 동작에 많은 변동성을 가지고 있다. DevOps와 MLOps는 많은 유사점을 공유하고 있지만, MLOps는 데이터 중심의 계산 집약적인 ML 워크플로우가 야기하는 고유한 문제를 해결하기 위해 보다 전문화된 툴과 관행을 필요로 한다.

MLOps의 중요성과 이점
ML은 기업이 데이터를 분석하고 의사 결정을 내리고 운영을 최적화하는 방식에 혁명을 일으켰다. 이를 통해 조직은 패턴, 추세 및 통찰력을 보여주는 강력한 데이터 기반 모델을 생성하여 더 많은 정보에 입각한 의사 결정과 더 효과적인 자동화를 유도할 수 있게 되었다. 그러나 ML 모델을 효과적으로 배포하고 관리하는 것은 어려울 수 있으며, 여기서 MLOps가 작동하게 된다. MLOps는 다음과 같은 다양한 이점을 제공하기 때문에 현대 기업에서 점점 더 중요해지고 있다.
 * 개발 시간 단축: 조직은 ML 모델의 개발 라이프사이클을 가속화하여 시장 출시 시간을 단축하고 변화하는 시장 요구에 신속하게 대응할 수 있다. 또한 MLOps를 사용하면 데이터 수집, 모델 교육 및 구축에서 많은 작업을 자동화하여 리소스를 확보하고 전체 프로세스를 가속화할 수 있다.
 * 더 나은 모델 성능: MLOps를 사용하면 기업은 ML 모델의 성능을 지속적으로 모니터링하고 개선할 수 있다. MLOps는 ML 모델에 대한 자동화된 테스트 메커니즘을 용이하게 하여 모델 정확도, 모델 드리프트 및 데이터 품질과 관련된 문제를 감지한다. 조직은 이러한 문제를 조기에 해결하여 비즈니스 결과를 개선함으로써 ML 모델의 전반적인 성능과 정확성을 향상시킬 수 있다.
 * 보다 안정적인 구축: 다양한 프로덕션 환경에서 ML 모델을 보다 안정적이고 일관성 있게 구현할 수 있다. MLOps는 배포 프로세스를 자동화함으로써 운영 환경에서 실행할 때 배포 오류 및 서로 다른 환경 간의 불일치 위험을 줄인다.
 * 비용 절감 및 효율성 향상: MLOps를 구현하면 조직이 비용을 절감하고 전반적인 효율성을 향상하는 데 도움이 될 수 있다. 데이터 처리, 모델 교육 및 구축과 관련된 많은 작업을 자동화함으로써 조직은 수동 개입의 필요성을 줄여 보다 효율적이고 비용 효율적인 워크플로우를 제공할 수 있다.

MLOps 라이프사이클
 * 지속적인 통합(Continuous Integration)
   지속적인 통합은 코드 및 데이터에 대한 변경 사항을 지속적으로 테스트하고 검증하여 정의된 표준을 충족하는지 확인하는 것을 포함한다. MLOps에서 CI는 ML 모델 및 지원 코드에 대한 새로운 데이터 및 업데이트를 통합한다. CI는 팀이 개발 프로세스 초기에 문제를 파악할 수 있도록 도와주기 때문에 보다 효과적으로 협업하고 고품질 ML 모델을 유지할 수 있다.
   * 자동화된 데이터 유효성 검사를 통해 데이터 무결성과 품질을 보장
   * 모델 아키텍처 및 하이퍼파라미터의 변화를 추적하는 모델 버전 제어
   * 모델 코드의 자동화된 단위 테스트는 코드가 생산 저장소에 병합되기 전에 문제점 파악
 * 연속 배포(CD)
   연속배포는 ML 모델 또는 애플리케이션과 같은 운영 환경에 대한 소프트웨어 업데이트를 자동으로 릴리스하는 것이다. MLOps에서 CD는 ML 모델의 구축이 원활하고 안정적이며 일관적인지 확인하는 데 중점을 둔다.
 * CD를 사용하면 구현 중 오류의 위험을 줄일 수 있으며 변화하는 비즈니스 요구사항에 대응하여 ML 모델을 보다 쉽게 유지 및 업데이트할 수 있다.
   * 모델 업데이트 통합 및 테스트를 위한 Jenkins 또는 CircleCI와 같은 지속적인 배포 툴을 사용하여 ML 파이프라인을 자동화한 다음 운영에 배포한다.
   * 도커(Docker)와 같은 기술을 사용하여 ML 모델을 컨테이너화하여 일관된 배포 환경을 구현함으로써 잠재적인 배포 문제를 줄일 수 있다.
   * 롤링 배포 또는 청록색 배포를 구현하면 다운타임을 최소화하고 문제가 있는 업데이트를 쉽게 롤백할 수 있다.
 * 지속적인 교육(CT)
   지속적인 교육은 새로운 데이터를 사용할 수 있게 되거나 시간이 지남에 따라 기존 데이터가 변경됨에 따라 ML 모델을 업데이트하는 것을 포함한다. MLOps의 이러한 필수적인 측면은 ML 모델이 최신 데이터를 고려하고 모델 드리프트를 방지하면서 정확하고 효과적인 상태를 유지하도록 보장한다. 새로운 데이터로 모델을 정기적으로 교육하면 최적의 성능을 유지하고 더 나은 비즈니스 결과를 얻을 수 있다.
   * 최신 정확도를 유지하기 위해 모델 재교육을 트리거하는 정책(즉, 정확도 임계값) 설정
   * 적극적인 학습 전략을 사용하여 교육을 위한 귀중한 새 데이터를 수집하는 데 우선 순위 부여
   * 앙상블 방법을 사용하여 다양한 데이터 하위 집합에서 훈련된 여러 모델을 결합하여 지속적인 모델 개선 및 변화하는 데이터 패턴 적응
 * 지속적인 모니터링(Continuous Monitoring)
   지속적인 모니터링은 생산 환경에서 ML 모델의 성능을 지속적으로 분석하여 잠재적인 문제를 식별하고 모델이 정의된 표준을 충족하는지 확인하며 전반적인 모델 효과를 유지한다. MLOps 실무자는 CM을 사용하여 예측의 정확성과 신뢰성을 손상시킬 수 있는 모델 드리프트 또는 성능 저하와 같은 문제를 감지한다.
 * 정기적으로 모델의 성능을 모니터링함으로써 조직은 ML 모델이 효과적으로 유지되고 원하는 결과를 생성할 수 있도록 모든 문제를 사전에 해결할 수 있다.
   * 정밀도, 리콜 또는 기타 도메인별 메트릭과 같은 생산 중인 모델의 주요 성능 지표(KPI) 추적
   * 모델 상태의 실시간 시각화를 위한 모델 성능 모니터링 대시보드 구현
   * 개념 드리프트를 식별하고 처리하기 위해 이상 탐지 기술을 적용하여 모델이 변화하는 데이터 패턴에 적응하고 시간이 지남에 따라 정확도를 유지할 수 있도록 보장

MLOps 도구 및 기술
 * MLFlow
   * 특장점
     * 모듈성: 모듈식 아키텍처. 독립적인 구성요소(Tracking, Projects, Model, Registry)로 구성되어 있어 개별적으로 또는 조합하여 사용할 수 있으므로 사용자가 모든 구성요소를 채택할 필요 없이 정확한 요구에 맞게 플랫폼 조정 가능
     * Language Agnostic: Python, R 및 Java를 포함한 여러 프로그래밍 언어를 지원하므로 다양한 스킬을 가진 다양한 사용자가 액세스 가능
     * Popular Libraries와의 통합: TensorFlow, PyTorch 및 Scikit-learn과 같은 인기 있는 ML 라이브러리등과의 호환성을 통해 사용자는 완전히 새로운 에코시스템을 채택하거나 현재 툴을 변경하지 않고도 MLflow를 기존 워크플로우에 원활하게 통합 가능
     * Active-Open-source Community: 오픈 소스 커뮤니티와 MLOps 공간의 새로운 트렌드와 요구사항에 따라 플랫폼을 최신 상태로 유지
     * 실시간 모델 관찰 가능성 도구에 중점을 둔 엔드 투 엔드 MLOps 도구
   * 약점
     * TFX 또는 Kubflow Pipeles에서 제공하는 것과 같은 통합된 내장 파이프라인 조정 및 실행 기능이 필요
     * 사용자는 복잡한 엔드 투 엔드 워크플로우를 조정하고 파이프라인 작업 실행을 자동화하기 위해 외부 도구 또는 사용자 지정 스크립팅 필요로 함
     * 복잡한 파이프라인 조정을 위한 보다 효율적이고 즉각적인 지원을 원하는 조직은 MLflow의 기능을 개선할 필요가 있음을 발견하고 파이프라인 관리 요구사항을 해결하기 위한 대체 플랫폼이나 통합을 모색
     
     
 * 쿠베플로우(Kubeflow)
   * 특장점
     * ML 라이프사이클의 다양한 측면에 맞게 조정된 일련의 구성요소를 갖춘 포괄적인 MLOps 플랫폼
     * Kubernetes의 강력한 결합
     * Kubeflow Pipeles 구성 요소를 통해 실험 추적 기능을 제공
   * 약점
     * 더 가파른 학습 곡선: Kubernetes의 개념과 도구에 더 익숙해질 필요가 있는 사용자들에게 더 가파른 학습 곡선으로 이어질 수 있음
     * 제한된 언어 지원: Kubeflow는 처음에는 TensorFlow에 중점을 두고 개발되었으며, PyTorch 및 MXNet과 같은 다른 ML 프레임워크에 대한 지원을 확대했지만 여전히 TensorFlow 생태계에 대해 더 큰 편향을 가지고 있음
     * 인프라 복잡성: 기존 Kubernetes 설정이 없는 조직에 추가적인 인프라 관리 복잡성과 오버헤드 가능성
     * 실험 추적에 대한 집중력 감소: MLflow보다 사용자 친화적이지 않음
     * Non-Kubernetes Systems와의 통합: Kubernetes-Native 설계로 인해 다른 Non-Kubernetes 기반 시스템 또는 독점 인프라와의 통합 기능 제한
 * 텐서플로우 확장(TensorFlow Extended)
   * 특장점
     * 텐서플로우 통합: TensorFlow 에코시스템과의 원활한 통합
     * 프로덕션 준비 상태: TFX는 프로덕션 환경을 염두에 두고 구축되었으며, 견고성, 확장성 및 미션 크리티컬 ML 워크로드를 지원 기능 제공으로 데이터 검증 및 사전 처리부터 모델 배포 및 모니터링에 이르기까지 모든 것을 처리하여 모델이 생산 준비가 완료되고 규모에 맞게 안정적인 성능 제공 보장
     * 엔드 투 엔드 워크플로우: ML 라이프사이클의 다양한 단계를 처리하기 위한 광범위한 구성요소 제공. TFX는 데이터 수집, 변환, 모델 교육, 검증 및 서빙을 지원하여 워크플로우의 재현성과 일관성을 보장하는 엔드 투 엔드 파이프라인 구축 지원
     * 확장성: TFX의 구성 요소는 사용자 지정이 가능하며, 필요에 따라 사용자가 직접 구성 요소를 생성하고 통합할 수 있음. 그래서, 특정 요구사항에 맞게 맞춤형 솔루션을 구현 가능
   * 약점
     * 다른 ML 프레임워크에 의존하거나 보다 언어에 구애받지 않는 솔루션을 선호하는 조직에는 한계. 예를 들어, PyTorch 또는 Scikit-learn과 같은 프레임워크를 사용하는 사용자는 요구 사항에 더 적합한 다른 MLOps 툴은 별도 고려 필요
 * 메타플로우(Metaflow)
   * 특장점
     * 메타플로우는 넷플릭스가 개발한 MLOps 플랫폼으로, 복잡한 실제 데이터 사이언스 프로젝트를 간소화하기 위해 설계되어 복잡한 ML 워크플로우를 단순화하는 데 중점을 두고 있음
     * 워크플로우 관리: 복잡한 실제 ML 워크플로우를 효과적으로 관리. 사용자는 내장된 버전, 의존성 관리 및 파이썬 기반 도메인별 언어를 통해 복잡한 처리 및 모델 교육 단계를 설계, 구성 및 실행
     * 관측 가능: 각 파이프라인 단계 후에 입력과 출력을 관찰할 수 있는 기능 제공으로 파이프라인의 다양한 단계에서 데이터 쉽게 추적 가능
     * 확장성: 로컬 환경에서 클라우드로 워크플로우를 쉽게 확장 가능. AWS 배치, S3, Step Functions와 같은 AWS 서비스와 긴밀하게 통합. 이를 통해 사용자는 기본 리소스에 대한 걱정 없이 워크로드를 쉽게 실행하고 대규모로 구현 가능
     * 내장 데이터 관리: 워크플로우가 사용하는 데이터셋을 자동으로 추적하여 효율적인 데이터 관리 및 버전 관리를 위한 툴 제공. 다양한 파이프라인 실행 간에 데이터 일관성을 보장
     * 내결함성 및 복원력: 예기치 않은 장애, 리소스 제약 및 요구사항 변경과 같은 실제 ML 프로젝트에서 발생하는 문제를 처리 설계. 자동 오류 처리, 재시도 메커니즘, 실패하거나 중단된 단계를 재개할 수 있는 기능 등을 제공하여 다양한 상황에서 워크플로우를 안정적이고 효율적으로 실행할 수 있도록 보장
   * 약점
     * 제한된 딥러닝 지원: 초기에 딥러닝보다는 일반적인 데이터 과학 워크플로우와 전통적인 ML 방식에 초점을 맞추어 개발. 이로 인해 텐서플로우나 PyTorch와 같은 딥러닝 프레임워크를 주로 사용하는 팀이나 프로젝트에 적합하지 않을 수 있음.
     * 실험 추적: 워크플로우 관리 및 인프라 간소화에 초점을 맞추고 있기 때문에 MLflow 또는 Weights & Bias와 같은 전용 실험 추적 플랫폼보다 추적 기능 약함
     * Kubernetes-네이티브 오케스트레이션: 전체 ML 파이프라인을 Kubernetes 리소스로 실행할 수 있는 Kubernetes-네이티브 파이프라인 오케스트레이션이 Kubernetes와 같은 도구에서 찾을 수 없음
     * 언어 지원: Python을 주로 지원하기 때문에 ML 프로젝트에서 R 또는 Java와 같은 다른 프로그래밍 언어를 사용하는 팀은 사용하기 어려움.
 * 젠ML(ZenML)
   * 특장점
     * ML 을 재현 가능하고 유지 가능하며 확장 가능한 오픈 소스 MLOps 프레임워크으로 확장성이 높고 적응성이 뛰어난 MLOps 프레임워크로 설계. 그래서, ML 워크플로우의 유지보수성, 재현성 및 확장성을 개선하고자 하는 조직에 특히 적합
     * ML 파이프라인 추상화: 간단한 추상화를 사용하여 ML 파이프라인을 정의할 수 있는 Pythonic 방법을 제공하여 데이터 수집, 전처리, 훈련 및 평가와 같은 ML 라이프사이클의 다양한 단계를 쉽게 생성하고 관리
     * 재현성: 재현성을 강력하게 강조하여 파이프라인 구성 요소가 정확한 메타데이터 시스템을 통해 버전화되고 추적되도록. 이를 통해 ML 실험을 일관되게 복제할 수 있어 불안정한 환경, 데이터 또는 종속성과 관련된 문제를 방지
     * 백엔드 오케스트레이터 통합: Apache Airway, Kubflow 등과 같은 다양한 백엔드 오케스트레이터 지원. 이러한 유연성을 통해 사용자는 로컬 머신, Kubernetes 또는 클라우드 환경에서 파이프라인을 관리하는 경우 등 필요와 인프라에 가장 적합한 백엔드를 선택 가능
     * 확장성: 사용자가 다양한 파이프라인 단계에 대한 사용자 정의 로직을 작성하고 선호하는 도구 또는 라이브러리와 쉽게 통합할 수 있는 확장성이 뛰어난 아키텍처를 제공. 이를 통해 조직은 ZenML을 특정 요구사항 및 워크플로우에 맞게 조정 가능
     * 데이터셋 버전 관리: 효율적인 데이터 관리 및 버전 관리에 중점을 두어 파이프라인이 올바른 버전의 데이터 및 아티팩트에 액세스할 수 있도록 보장. 내장된 데이터 관리 시스템을 통해 사용자는 다양한 파이프라인 실행 간에 데이터 일관성을 유지할 수 있으며 ML 워크플로우의 투명성을 높일 수 있음.
     * ML 프레임워크와의 높은 통합: TensorFlow, PyTorch 및 Scikit-learn을 포함한 인기 있는 ML 프레임워크와의 원활한 통합 제공. 실무자는 ZenML의 파이프라인 관리를 활용하면서 기존 기술과 도구를 활용 가능

MLOps 솔루션 도입을 위한 평가 요소
 * 조직 규모 및 팀 구조: 데이터 과학 및 엔지니어링 팀의 규모, 전문성 수준 및 협업이 필요한 정도 고려. 더 큰 그룹이나 더 복잡한 계층 구조는 강력한 협업 및 통신 기능을 갖춘 툴의 이점 고려
 * ML 모델의 복잡성 및 다양성: 조직에서 사용되는 알고리즘, 모델 아키텍처 및 기술의 범위를 평가. 일부 MLOps 도구는 특정 프레임워크 또는 라이브러리를 충족하는 반면, 다른 도구는 보다 광범위하고 다재다능한 지원 기능 제공
 * 자동화 및 확장성 수준: 데이터 전처리, 모델 교육, 배포 및 모니터링과 같은 작업에 자동화가 필요한 정도 결정. 또한 일부 MLOps 툴은 계산을 확장하고 많은 양의 데이터를 처리하는 데 더 나은 지원을 제공하므로 조직에서 확장성의 중요성 이해 필요
 * 통합 및 호환성: MLOps 도구와 기존 기술 스택, 인프라 및 워크플로우의 호환성 고려. 현재 시스템과의 원활한 통합을 통해 보다 원활한 채택 프로세스를 보장하고 진행 중인 프로젝트의 중단을 최소화 고려
 * 사용자 정의 및 확장성: ML 워크플로우에 필요한 사용자 지정 수준과 확장성 평가. 일부 툴은 보다 유연한 API 또는 플러그인 아키텍처를 제공하여 특정 요구 사항 고려
 * 비용 및 라이센싱: MLOps 도구의 가격 구조와 라이센싱 옵션을 염두에 두고 조직의 예산 및 리소스 제약 조건 고려
 * 보안 및 컴플라이언스: MLOps 툴이 보안, 데이터 개인 정보 보호 및 컴플라이언스 요구사항을 얼마나 잘 해결하는지 평가
 * 지원 및 커뮤니티: 문서의 품질, 커뮤니티 지원 및 필요할 때 전문 지원의 가용성을 고려. 적극적인 커뮤니티와 대응적인 지원은 문제를 탐색하거나 모범 사례를 모색할 때 유용할 수 있음.
